Мы работали с двумя моделями --- BERT и многоязыковой BERT. Также мы рассмотрели две задачи: aspect-base sentiment analysis и entity-base sentiment analisys. При это в первом случае нам не нужно было использовать позицию токена в тексте. Соотвественно на англоязычном датасете оценок ресторанов SemEval14_ABSA с помощью обычного BERT мы получили точность 86% и f1 75%. Сам apsect мы писали после предложения через токен [SEP], а классификатор навешивали на токен [CLS].

Далее мы приступили к задаче entity-based sentiment analisys. На том же датасете оценок ресторанов с помощью англоязычного BERT мы получили точность 80% и f1 63%. При этом мы не вполне верно обрабтывали эмебеддинги. Вероятно, этот момент можно улучшить.

Далее мы постпули следующим образом. Теоретически, тональность не зависит от сущности. По этому поводу мы заменяли ее токеном [MASK] и навешивали классификактор на токен [CLS]. Однако, такой подход не дал хороший результатов. На все том же датасете SemEval14_ASBA с помощью многоязыкового BERT мы получили точность 78% и f1 57%. На русскоязычном датасете SentiRuEval2015_rest все гораздо хуже: accuracy -- 74%, f1 macro 33%. Но, во-первых, многоязыковой BERT можно обучать и на английском, и на русском датасете сразу. Во-вторых, можно оставить только классификацию на positive и negative, оставляя классификацию на тонально окращенные и не окрашенные сущности как отдельную задачу. В третьих, поскольку мы работаем с сущностями, закрывая их масками, то нам не важна специфика ресторанов и пр. Так что, если успеем, мы объединим датасеты и обучим многоязыковый BERT на них.
